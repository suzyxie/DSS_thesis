# -*- coding: utf-8 -*-
"""Thesis model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f2BjEZWCYbrymC7AOtZxhVRtCh4fhFtF
"""

import os
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import cv2
from google.colab.patches import cv2_imshow
import tensorflow as tf
from keras.callbacks import ModelCheckpoint
from tensorflow.keras import layers
from tensorflow.keras.optimizers.schedules import PolynomialDecay
from tensorflow.keras.losses import CategoricalFocalCrossentropy,KLDivergence
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.metrics import OneHotMeanIoU

from google.colab import drive
drive.mount('/content/drive')

original_images_train = "/content/drive/MyDrive/Thesis Dataset /Original dataset/train/train-org-img"
original_images_val = "/content/drive/MyDrive/Thesis Dataset /Original dataset/validation /val-org-img "
original_images_test= '/content/drive/MyDrive/Thesis Dataset /Original dataset/test/test-org-img'
original_masks_train = '/content/drive/MyDrive/Thesis Dataset /Original dataset/train/train-label-img'
original_masks_val = '/content/drive/MyDrive/Thesis Dataset /Original dataset/validation /val-label-img'
original_masks_test = '/content/drive/MyDrive/Thesis Dataset /Original dataset/test/test-label-img'

"""##EDA"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg


# Define the mapping between denormalized pixel values and classes
pixel_value_to_class = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    6: 'Tree',
    7: 'Vehicle',
    8: 'Pool',
    9: 'Grass',
    # Add more mappings as needed
}

# Initialize a dictionary to store class counts
class_counts = {class_label: 0 for class_label in pixel_value_to_class.values()}

# Get a list of image files in the training data folder
image_files = os.listdir(training_data)

# Initialize a list to store denormalized pixel values
denormalized_pixel_values_list = []

# Count occurrences of each unique pixel value and save denormalized values
for image_file in image_files:
    image_path = os.path.join(training_data, image_file)
    img = mpimg.imread(image_path)
    unique_values = np.unique(img) * 255.0  # Assuming denormalization to [0, 255] range

    # Map unique pixel values to classes and update class counts
    for unique_value in unique_values:
        class_label = pixel_value_to_class.get(int(unique_value), 'Unknown')  # Convert to int for matching denormalized values
        class_counts[class_label] += 1  # Count each pixel separately

    # Append denormalized pixel values to the list
    denormalized_pixel_values_list.append(unique_values)

# Convert each sublist to a NumPy array
denormalized_pixel_values_array = [np.array(sublist) for sublist in denormalized_pixel_values_list]

# Save the denormalized pixel values as a NumPy array
np.save('/content/drive/MyDrive/Thesis Dataset /denormalized_pixel_values_training.npy', denormalized_pixel_values_list)

# Print class distribution
print("Class Distribution:")
for class_label, count in class_counts.items():
    print(f"{class_label}: {count} pixels")

fig, ax = plt.subplots(figsize=(10, 6))
bar_width = 0.5
bar_positions = np.arange(len(class_counts))

ax.bar(bar_positions, class_counts.values(), width=bar_width, align='center', tick_label=class_counts.keys())
ax.set_xticklabels(class_counts.keys(), rotation=45, ha="right")  # Rotate x-axis labels

ax.set_xlabel('Class')
ax.set_ylabel('Class Count')
ax.set_title('Class Distribution in Training Set')

plt.show()

import cv2
import os



# List the files in the directory
image_files = os.listdir(original_images_train)

# Create a set to store unique image sizes
unique_sizes = set()

for image_file in image_files:
    image_path = os.path.join(original_images_train, image_file)
    img = cv2.imread(image_path)

    # Check if the image file is valid
    if img is not None:
        height, width, _ = img.shape
        size_tuple = (height, width)
        unique_sizes.add(size_tuple)

# Print the unique image sizes
for size in unique_sizes:
    print(f"Unique Image Size: Height = {size[0]}, Width = {size[1]}")

"""##Pre-processing data

###Resize the images and masks(720*720)
"""

# Define the directory paths for the resized data
resized_train_dir = '/content/drive/MyDrive/Thesis Dataset/resized_train'
resized_val_dir = '/content/drive/MyDrive/Thesis Dataset/resized_val'
resized_test_dir = '/content/drive/MyDrive/Thesis Dataset/resized_test'

# Create the directories if they don't exist
os.makedirs(resized_train_dir, exist_ok=True)
os.makedirs(resized_val_dir, exist_ok=True)
os.makedirs(resized_test_dir, exist_ok=True)

# Within each resized data directory, create subdirectories for images and masks
os.makedirs(os.path.join(resized_train_dir, 'images'), exist_ok=True)
os.makedirs(os.path.join(resized_val_dir, 'images'), exist_ok=True)
os.makedirs(os.path.join(resized_test_dir, 'images'), exist_ok=True)
os.makedirs(os.path.join(resized_train_dir, 'masks'), exist_ok=True)
os.makedirs(os.path.join(resized_val_dir, 'masks'), exist_ok=True)
os.makedirs(os.path.join(resized_test_dir, 'masks'), exist_ok=True)


target_size = (720, 720)

# Define a function to resize images and masks and save them
def resize_images_and_masks(image_directory, mask_directory, target_size, output_dir):
    for filename in os.listdir(image_directory):
        if filename.endswith('.jpg'):  # Adjust the file extension if needed
            img_path = os.path.join(image_directory, filename)
            img = cv2.imread(img_path)
            if img is not None:
                resized_img = cv2.resize(img, target_size)
                img_output_path = os.path.join(output_dir, 'images', filename)
                cv2.imwrite(img_output_path, resized_img)

                # Load and resize the corresponding mask
                mask_path = os.path.join(mask_directory, filename.replace('.jpg', '_lab.png'))
                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask is not None:
                    resized_mask = cv2.resize(mask, target_size,interpolation=cv2.INTER_NEAREST)
                    mask_output_path = os.path.join(output_dir, 'masks', filename.replace('.jpg', '_lab.png'))
                    cv2.imwrite(mask_output_path, resized_mask)

# Call the function to resize and save images and masks for each dataset
resize_images_and_masks(original_images_train, original_masks_train, target_size, resized_train_dir)
resize_images_and_masks(original_images_val, original_masks_val, target_size, resized_val_dir)
resize_images_and_masks(original_images_test, original_masks_test, target_size, resized_test_dir)

"""###normalization"""

#check if the images are already normlized or not
import matplotlib.pyplot as plt
import cv2
import os

# Define the directory path for the images
image_directory = '/content/drive/MyDrive/Thesis Dataset /Resized_data /resized_train/images'

# Check the first 10 images
num_images_to_check = 10

# Create subplots with two rows
fig, axs = plt.subplots(2, 5, figsize=(15, 6))

for i, filename in enumerate(os.listdir(image_directory)):
    if i >= num_images_to_check:
        break  # Stop after loading 10 images

    if filename.endswith('.jpg'):
        # Load an image
        image_path = os.path.join(image_directory, filename)
        image = cv2.imread(image_path)

        if image is not None:
            # Display the image in the appropriate subplot
            row = i // 5
            col = i % 5
            axs[row, col].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            axs[row, col].set_title(f"Image {i + 1}")

            # Show the pixel value range (min, max)
            pixel_range = (image.min(), image.max())
            axs[row, col].set_xlabel(f"Pixel Range: {pixel_range}")

# Hide any empty subplots
for i in range(num_images_to_check, 10):
    row = i // 5
    col = i % 5
    axs[row, col].axis('off')

plt.tight_layout()
plt.show()

#Normalization
import os
import cv2
import numpy as np

# Define the directory paths for the resized data
resized_train_dir = '/content/drive/MyDrive/Resized_data_720/resized_train'
resized_val_dir = '/content/drive/MyDrive/Resized_data_720/resized_val'
resized_test_dir = '/content/drive/MyDrive/Resized_data_720/resized_test'

def normalize_images_in_directory(directory):
    for filename in os.listdir(directory):
        if filename.endswith('.jpg'):
            # Load an image
            img_path = os.path.join(directory, filename)
            img = cv2.imread(img_path)

            if img is not None:
                # Normalize the image to the range [0, 1]
                img_normalized = img / 255.0

                # Save the normalized image back to the directory
                normalized_img_path = os.path.join(directory, filename)
                cv2.imwrite(normalized_img_path, (img_normalized * 255).astype(int))

# Call the function to normalize images in each directory
normalize_images_in_directory(resized_train_dir)
normalize_images_in_directory(resized_val_dir)
normalize_images_in_directory(resized_test_dir)

#check if the dataset is normalized between 0 and 1
import cv2
import numpy as np

# Load an image
img_path = '/content/drive/MyDrive/Resized_data_720/resized_train/images/10165.jpg'
img = cv2.imread(img_path)

if img is not None:
    # Check pixel value range
    pixel_min = img.min() / 255.0  # Scale to [0, 1]
    pixel_max = img.max() / 255.0  # Scale to [0, 1]

    print(f"Minimum Pixel Value: {pixel_min:.3f}")
    print(f"Maximum Pixel Value: {pixel_max:.3f}")
else:
    print("Error loading the image.")

"""###Class deduction"""

resized_masks_train = "/content/drive/MyDrive/Resized_data_720/resized_train/masks"
resized_masks_val = "/content/drive/MyDrive/Resized_data_720/resized_val/masks"
resized_masks_test = "/content/drive/MyDrive/Resized_data_720/resized_test/masks"

#set the classes moved to "Background" pixel values
background_class_value = 0

class_values_to_remove = [6, 8, 9]

def update_masks_in_directory(mask_directory):
    # Iterate through the mask images in the specified directory
    for filename in os.listdir(mask_directory):
        if filename.endswith('.png'):
            mask_path = os.path.join(mask_directory, filename)
            mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)

            if mask is not None:
                # Set pixels belonging to the missing classes to the background class value (0)
                for class_value_to_remove in class_values_to_remove:
                    mask[mask == class_value_to_remove] = background_class_value

                # Save the updated mask back to the directory
                cv2.imwrite(mask_path, mask)

# Update masks in your specified directories
update_masks_in_directory(resized_masks_train)
update_masks_in_directory(resized_masks_val)
update_masks_in_directory(resized_masks_test)

new_class_mapping = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    7: 'Vehicle'
}
#test on one sample
class_reduction_sample_directory= '/content/drive/MyDrive/Resized_data_720/resized_train/masks/6797_lab.png'
def display_single_mask(mask_path, title):
    mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
    if mask is not None:
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))
        # Display the mask
        axes[0].imshow(mask, cmap='viridis')
        axes[0].set_title(f"{title}")
        axes[0].axis('off')
        # Denormalize and display class labels
        unique_values, counts = np.unique(mask, return_counts=True)
        class_labels = [new_class_mapping.get(pixel_value, 'Unknown') for pixel_value in unique_values]
        class_info = [f"{label}: {count}" for label, count in zip(class_labels, counts)]
        class_labels_text = '\n'.join(class_info)
        axes[1].text(0.5, 0.5, f"Unique Values with Counts:\n{class_labels_text}", fontsize=12, ha='center')
        axes[1].axis('off')
        plt.show()

        return unique_values, counts  # Return the unique values and counts

# Display the single mask and get unique values with counts
unique_values, counts = display_single_mask(class_reduction_sample_directory, "Class_reduction_mask")

total_pixels = np.sum(counts)
for label, count in zip(unique_values, counts):
    class_label = new_class_mapping.get(label, 'Unknown')
    proportion = count / total_pixels
    print(f"Class Label: {class_label}, Count: {count}, Proportion: {proportion:.2%}")

mask = cv2.imread(class_reduction_sample_directory,cv2.IMREAD_UNCHANGED)
mask

#original mask
original_class = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    6: 'Tree',
    7: 'Vehicle',
    8: 'Pool',
    9: 'Grass',

}
sample_directory= '/content/drive/MyDrive/Thesis Dataset /train-label-img/6797_lab.png'
def display_single_mask(mask_path, title):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is not None:
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))
        # Display the mask
        axes[0].imshow(mask, cmap='viridis')
        axes[0].set_title(f"{title}")
        axes[0].axis('off')
        # Calculate unique values and their counts
        unique_values, counts = np.unique(mask, return_counts=True)
        class_labels = [original_class.get(pixel_value, 'Unknown') for pixel_value in unique_values]
        class_info = [f"{label}: {count}" for label, count in zip(class_labels, counts)]
        class_labels_text = '\n'.join(class_info)
        axes[1].text(0.5, 0.5, f"Unique Values with Counts:\n{class_labels_text}", fontsize=12, ha='center')
        axes[1].axis('off')
        plt.show()

        return unique_values, counts  # Return the unique values and counts

# Display the single mask and get unique values with counts
unique_values, counts = display_single_mask(sample_directory, "original_Mask")


total_pixels = np.sum(counts)
for label, count in zip(unique_values, counts):
    class_label = original_class.get(label, 'Unknown')
    proportion = count / total_pixels
    print(f"Class Label: {class_label}, Count: {count}, Proportion: {proportion:.2%}")

#resized mask
resized_sample_directory= '/content/drive/MyDrive/Thesis Dataset /Resized_data /resized_train/masks/6797_lab.png'
def display_single_mask(mask_path, title):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is not None:
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))
        # Display the mask
        axes[0].imshow(mask, cmap='viridis')
        axes[0].set_title(f"{title}")
        axes[0].axis('off')
        # Denormalize and display class labels
        unique_values, counts = np.unique(mask, return_counts=True)
        class_labels = [original_class.get(pixel_value, 'Unknown') for pixel_value in unique_values]
        class_info = [f"{label}: {count}" for label, count in zip(class_labels, counts)]
        class_labels_text = '\n'.join(class_info)
        axes[1].text(0.5, 0.5, f"Unique Values with Counts:\n{class_labels_text}", fontsize=12, ha='center')
        axes[1].axis('off')
        plt.show()

        return unique_values, counts  # Return the unique values and counts

# Display the single mask and get unique values with counts
unique_values, counts = display_single_mask(resized_sample_directory, "Resized_mask")

total_pixels = np.sum(counts)
for label, count in zip(unique_values, counts):
    class_label = original_class.get(label, 'Unknown')
    proportion = count / total_pixels
    print(f"Class Label: {class_label}, Count: {count}, Proportion: {proportion:.2%}")

"""### Data Augmentation"""

!pip install -q -U albumentations
!echo "$(pip freeze | grep albumentations) is successfully installed"

# Define a pipeline for image and mask augmentations
from albumentations import Compose
import albumentations as A


image_transforms = A.Compose([
    # Composition and Blending
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.OneOf([
        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),
        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    ], p=0.5),
    # Weather Effects
    A.RandomRain(p=0.5),
    # Lighting Effects
    A.RandomShadow(p=0.5),
    # RandomSizedCrop
    A.RandomSizedCrop(min_max_height=(200, 300), height=720, width=720, p=0.5)])


# Apply the same composition to masks
mask_transforms = A.Compose([
     A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.OneOf([
        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),
        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
    ], p=0.5),
    A.RandomRain(p=0.5),
    A.RandomShadow(p=0.5),
    A.RandomSizedCrop(min_max_height=(200, 300), height=720, width=720, p=0.5)])

# Define the directories for augmented data
augmented_images_dir = '/content/drive/MyDrive/Resized_data_720/augmented data/images'
augmented_masks_dir = '/content/drive/MyDrive/Resized_data_720/augmented data/masks'


resized_images_train_720= "/content/drive/MyDrive/Resized_data_720/resized_train/images"
resized_masks_train_720= "/content/drive/MyDrive/Resized_data_720/resized_train/masks"
image_files = os.listdir(resized_images_train_720)

# Iterate through each image file
for image_file in image_files:
    # Load the image and corresponding mask
    image_path = os.path.join(resized_images_train_720, image_file)
    mask_path = os.path.join(resized_masks_train_720, image_file.replace('.jpg', '_lab.png'))

    image = cv2.imread(image_path)
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)


    # Apply the image and mask transformations
    augmented = image_transforms(image=image, mask=mask)
    augmented_image = augmented["image"]
    augmented_mask = augmented["mask"]

    # Save the augmented image and mask
    augmented_image_path = os.path.join(augmented_images_dir, image_file)
    augmented_mask_path = os.path.join(augmented_masks_dir, image_file.replace('.jpg', '.png'))

    cv2.imwrite(augmented_image_path, augmented_image)
    cv2.imwrite(augmented_mask_path, augmented_mask)

Agumented_images ="/content/drive/MyDrive/Resized_data_720/augmented data/images"
Agumented_masks= "/content/drive/MyDrive/Resized_data_720/augmented data/masks"

data = []
labels = []

for filename in os.listdir(Agumented_images):
    if filename.endswith(".jpg"):  # Assuming your images are in JPEG format
        # Load the image
        image = cv2.imread(os.path.join(Agumented_images, filename))
        data.append(image)

        # Load the corresponding mask
        mask_filename = os.path.join(Agumented_masks, filename.replace(".jpg", ".png"))
        mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE)
        labels.append(mask)

X_train_agumented = np.array(data)
y_train_agumented = np.array(labels)
np.save('/content/drive/MyDrive/Resized_data_720/X_train_agumented.npy', X_train_agumented)
np.save('/content/drive/MyDrive/Resized_data_720/y_train_agumented.npy', y_train_agumented)

num_classes = 7
y_train_agumented_reshaped = np.zeros((y_train_agumented.shape[0], y_train_agumented.shape[1], y_train_agumented.shape[2], num_classes), dtype=np.uint8)

# Iterate over each class and create the respective channel
for class_idx in range(num_classes):
    y_train_agumented_reshaped[:, :, :, class_idx] = (y_train == class_idx).astype(np.uint8)

"""##Teacher Model"""

pip install segmentation-models

#resize the images and masks
import os
import cv2

# Define the target size
target_size = (720, 720)

# Define the directories where your images and masks are located
sample_images_dir = "/content/drive/MyDrive/sample dataset/images "
sample_masks_dir = "/content/drive/MyDrive/sample dataset/masks"

# Create a directory to save the resized images and masks
resized_images_dir = "/content/drive/MyDrive/sample dataset/resized_images"
resized_masks_dir = "/content/drive/MyDrive/sample dataset/resized_masks"

# Create the directories if they don't exist
os.makedirs(resized_images_dir, exist_ok=True)
os.makedirs(resized_masks_dir, exist_ok=True)

# List all files in the images directory
image_files = os.listdir(sample_images_dir)

# Iterate through the images and resize them
for image_file in image_files:
    # Load the image
    image_path = os.path.join(sample_images_dir, image_file)
    image = cv2.imread(image_path)

    # Resize the image to the target size
    resized_image = cv2.resize(image, target_size)

    # Save the resized image
    resized_image_path = os.path.join(resized_images_dir, image_file)
    cv2.imwrite(resized_image_path, resized_image)

    # Process the corresponding mask
    mask_file = image_file.replace('.jpg', '_lab.png')  # Assuming masks have the same name as images with a .png extension
    mask_path = os.path.join(sample_masks_dir, mask_file)

    # Load the mask
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

    # Resize the mask to the target size
    resized_mask = cv2.resize(mask, target_size)

    # Save the resized mask
    resized_mask_path = os.path.join(resized_masks_dir, mask_file)
    cv2.imwrite(resized_mask_path, resized_mask)

# Define the target data range for normalization (e.g., [0, 1])
min_value = 0
max_value = 1

# Define a function to normalize images in a directory
def normalize_images_in_directory(directory):
    for filename in os.listdir(directory):
        if filename.endswith('.jpg'):
            # Load an image
            img_path = os.path.join(directory, filename)
            img = cv2.imread(img_path)

            if img is not None:
                # Normalize the image to the specified range
                img_normalized = (img - img.min()) / (img.max() - img.min()) * (max_value - min_value) + min_value

                # Save the normalized image back to the directory
                normalized_img_path = os.path.join(directory, filename)
                cv2.imwrite(normalized_img_path, img_normalized * 255)  # Scale back to [0, 255] for saving as image

# Call the function to normalize images in each directory
normalize_images_in_directory(resized_images_dir)

train_images_720 ="/content/drive/MyDrive/Resized_data_720/resized_train/images"
train_masks_720= "/content/drive/MyDrive/Resized_data_720/resized_train/masks"

train_data = []
train_labels = []

for filename in os.listdir(train_images_720):
    if filename.endswith(".jpg"):  # Assuming your images are in JPEG format
        # Load the image
        image = cv2.imread(os.path.join(train_images_720, filename))
        train_data.append(image)

        # Load the corresponding mask
        mask_filename = os.path.join(train_masks_720, filename.replace(".jpg", "_lab.png"))
        mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE)
        train_labels.append(mask)

X_train_720 = np.array(train_data)
y_train_720 = np.array(train_labels)
np.save('/content/drive/MyDrive/Resized_data_720/X_train_720.npy', X_train_720)
np.save('/content/drive/MyDrive/Resized_data_720/y_train_720.npy', y_train_720)

val_images_720 = "/content/drive/MyDrive/Resized_data_720/resized_val/images"
val_masks_720 = "/content/drive/MyDrive/Resized_data_720/resized_val/masks"

val_data = []
val_labels = []

for filename in os.listdir(val_images_720):
    if filename.endswith(".jpg"):
        # Load the image
        image = cv2.imread(os.path.join(val_images_720, filename))
        val_data.append(image)

        # Load the corresponding mask
        mask_filename = os.path.join(val_masks_720, filename.replace(".jpg", "_lab.png"))
        mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE)
        val_labels.append(mask)

X_val_720 = np.array(val_data)
y_val_720 = np.array(val_labels)
np.save('/content/drive/MyDrive/Resized_data_720/X_val_720.npy', X_val_720)
np.save('/content/drive/MyDrive/Resized_data_720/y_val_720.npy', y_val_720)

test_images_720 = "/content/drive/MyDrive/Resized_data_720/resized_test/images"
test_masks_720 = "/content/drive/MyDrive/Resized_data_720/resized_test/masks"

test_data = []
test_labels = []

for filename in os.listdir(test_images_720):
    if filename.endswith(".jpg"):
        # Load the image
        image = cv2.imread(os.path.join(test_images_720, filename))
        test_data.append(image)

        # Load the corresponding mask
        mask_filename = os.path.join(test_masks_720, filename.replace(".jpg", "_lab.png"))
        mask = cv2.imread(mask_filename, cv2.IMREAD_GRAYSCALE)
        test_labels.append(mask)

X_test_720 = np.array(test_data)
y_test_720 = np.array(test_labels)
np.save('/content/drive/MyDrive/Resized_data_720/X_test_720.npy', X_test_720)
np.save('/content/drive/MyDrive/Resized_data_720/y_test_720.npy', y_test_720)

X_train = np.load('/content/drive/MyDrive/Resized_data_720/X_train_720.npy')
y_train = np.load('/content/drive/MyDrive/Resized_data_720/y_train_720.npy')
X_val = np.load('/content/drive/MyDrive/Resized_data_720/X_val_720.npy')
y_val = np.load("/content/drive/MyDrive/Resized_data_720/y_val_720.npy")

num_classes = 7
y_train_reshaped = np.zeros((y_train.shape[0], y_train.shape[1], y_train.shape[2], num_classes), dtype=np.uint8)

# Iterate over each class and create the respective channel
for class_idx in range(num_classes):
    y_train_reshaped[:, :, :, class_idx] = (y_train == class_idx).astype(np.uint8)

y_val_reshaped = np.zeros((y_val.shape[0], y_val.shape[1], y_val.shape[2], num_classes), dtype=np.uint8)

# Iterate over each class and create the respective channel
for class_idx in range(num_classes):
    y_val_reshaped[:, :, :, class_idx] = (y_val == class_idx).astype(np.uint8)

X_train = X_train.astype('float32')
y_train = y_train_reshaped.astype('float32')
X_val = X_val.astype('float32')
y_val = y_val_reshaped.astype('float32')

# PSPNet teacher model
import os
os.environ["SM_FRAMEWORK"] = "tf.keras"

from tensorflow import keras
import segmentation_models as sm
from segmentation_models import PSPNet,Linknet



teacher_model = PSPNet(backbone_name='resnet101',
                       classes= 7, input_shape=(720, 720, 3),
                       activation='softmax',
                       encoder_weights='imagenet',
                       downsample_factor= 8,
                       psp_conv_filters = 128,
                       psp_pooling_type='avg',
                       psp_dropout=None
                       )

teacher_model.summary()

"""##Final teacher model scripts and results are saved locally"""

import tensorflow as tf
from tensorflow.keras.optimizers.schedules import PolynomialDecay
from tensorflow.keras.losses import CategoricalFocalCrossentropy
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.metrics import OneHotMeanIoU

# Define your learning rate schedule with the given parameters
base_learning_rate = 0.0001
momentum = 0.9
weight_decay = 0.0001
power = 0.9
auxiliary_loss_weight = 0.4

# Calculate the total number of training steps (you need to adjust this based on your dataset and batch size)
total_steps = 10000

learning_rate_schedule = PolynomialDecay(
    initial_learning_rate=base_learning_rate,
    decay_steps=total_steps,
    end_learning_rate=0,  # You can set this to 0 or any other final learning rate you desire
    power=power
)

# Create the legacy Adam optimizer with the specified momentum and weight decay
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule, beta_1=momentum, beta_2=0.999, epsilon=1e-7, weight_decay=weight_decay)

# Compile your model using the custom optimizer and loss
teacher_model.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalFocalCrossentropy(),
                      metrics=[tf.keras.metrics.OneHotMeanIoU(num_classes=num_classes)])

history = teacher_model.fit(X_train, y_train,
                            validation_data=(X_val, y_val),
                            epochs= 100
                            )

from tensorflow.keras.models import load_model

teacher_model_trained = load_model("/content/drive/MyDrive/teacher_model_FCloss2_150epochs.keras")

"""## Student Models
avalible backbones ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'seresnet18', 'seresnet34', 'seresnet50', 'seresnet101', 'seresnet152', 'seresnext50', 'seresnext101', 'senet154', 'resnext50', 'resnext101', 'vgg16', 'vgg19', 'densenet121', 'densenet169', 'densenet201', 'inceptionresnetv2', 'inceptionv3', 'mobilenet', 'mobilenetv2', 'efficientnetb0', 'efficientnetb1', 'efficientnetb2', 'efficientnetb3', 'efficientnetb4', 'efficientnetb5', 'efficientnetb6', 'efficientnetb7']
"""

student_model1= PSPNet(backbone_name='mobilenet',
                       classes= 7, input_shape=(720, 720, 3),
                       activation='softmax',
                       encoder_weights= None,
                       downsample_factor= 4,
                       psp_conv_filters = 16,
                       psp_pooling_type='avg',
                       psp_dropout=None,
                       psp_use_batchnorm=False,
                       )

student_model1. summary()

"""##Knowledge Distillation"""

class Distiller(keras.Model):
    def __init__(self, student, teacher):
        super().__init__()
        self.teacher = teacher
        self.student = student

    def compile(
        self,
        optimizer,
        metrics,
        student_loss_fn,
        distillation_loss_fn,
        alpha=0.1,
        temperature=3,
    ):
        """ Configure the distiller.

        Args:
            optimizer: Keras optimizer for the student weights
            metrics: Keras metrics for evaluation
            student_loss_fn: Loss function of difference between student
                predictions and ground-truth
            distillation_loss_fn: Loss function of difference between soft
                student predictions and soft teacher predictions
            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn
            temperature: Temperature for softening probability distributions.
                Larger temperature gives softer distributions.
        """
        super().compile(optimizer=optimizer, metrics=metrics)
        self.student_loss_fn = student_loss_fn
        self.distillation_loss_fn = distillation_loss_fn
        self.alpha = alpha
        self.temperature = temperature

    def train_step(self, data):
        # Unpack data
        x, y = data

        # Forward pass of teacher
        teacher_predictions = self.teacher(x, training=False)

        with tf.GradientTape() as tape:
            # Forward pass of student
            student_predictions = self.student(x, training=True)

            # Compute losses
            student_loss = self.student_loss_fn(y, student_predictions)

            # Compute scaled distillation loss from https://arxiv.org/abs/1503.02531
            # The magnitudes of the gradients produced by the soft targets scale
            # as 1/T^2, multiply them by T^2 when using both hard and soft targets.
            distillation_loss = (
                self.distillation_loss_fn(
                    tf.nn.softmax(teacher_predictions / self.temperature, axis=1),
                    tf.nn.softmax(student_predictions / self.temperature, axis=1),
                )
                * self.temperature**2
            )

            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss

        # Compute gradients
        trainable_vars = self.student.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)

        # Update weights
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        # Update the metrics configured in `compile()`.
        self.compiled_metrics.update_state(y, student_predictions)

        # Return a dict of performance
        results = {m.name: m.result() for m in self.metrics}
        results.update(
            {"student_loss": student_loss, "distillation_loss": distillation_loss}
        )
        return results

    def test_step(self, data):
        # Unpack the data
        x, y = data

        # Compute predictions
        y_prediction = self.student(x, training=False)

        # Calculate the loss
        student_loss = self.student_loss_fn(y, y_prediction)

        # Update the metrics.
        self.compiled_metrics.update_state(y, y_prediction)

        # Return a dict of performance
        results = {m.name: m.result() for m in self.metrics}
        results.update({"student_loss": student_loss})
        return results

num_classes =7
base_learning_rate = 0.0001
momentum = 0.9
weight_decay = 0.0001
power = 0.9
auxiliary_loss_weight = 0.4

# Calculate the total number of training steps (you need to adjust this based on your dataset and batch size)
total_steps = 10000

learning_rate_schedule = PolynomialDecay(
    initial_learning_rate=base_learning_rate,
    decay_steps=total_steps,
    end_learning_rate=0,  # You can set this to 0 or any other final learning rate you desire
    power=power
)

# Create the legacy Adam optimizer with the specified momentum and weight decay
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule, beta_1=momentum, beta_2=0.999, epsilon=1e-7, weight_decay=weight_decay)
distiller = Distiller(student=student_model1, teacher=teacher_model_trained )
distiller.compile(
    optimizer=optimizer,
    metrics=[tf.keras.metrics.OneHotMeanIoU(num_classes=num_classes)],
    student_loss_fn=tf.keras.losses.CategoricalFocalCrossentropy(),
    distillation_loss_fn= tf.keras.losses.KLDivergence(),
    alpha=0.1,
    temperature=10
)

distiller.fit(X_train, y_train, epochs=10)

from tensorflow.keras.models import load_model
loaded_model = tf.saved_model.load("/content/drive/MyDrive/KD_mobilenet")