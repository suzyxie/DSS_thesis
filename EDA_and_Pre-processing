import os
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import cv2
from google.colab.patches import cv2_imshow
import tensorflow as tf
from keras.callbacks import ModelCheckpoint
from tensorflow.keras import layers
from tensorflow.keras.optimizers.schedules import PolynomialDecay
from tensorflow.keras.losses import CategoricalFocalCrossentropy,KLDivergence
from tensorflow.keras.callbacks import Callback
from tensorflow.keras.metrics import OneHotMeanIoU

from google.colab import drive
drive.mount('/content/drive')

original_images_train = "/content/drive/MyDrive/Thesis Dataset /Original dataset/train/train-org-img"
original_images_val = "/content/drive/MyDrive/Thesis Dataset /Original dataset/validation /val-org-img "
original_images_test= '/content/drive/MyDrive/Thesis Dataset /Original dataset/test/test-org-img'
original_masks_train = '/content/drive/MyDrive/Thesis Dataset /Original dataset/train/train-label-img'
original_masks_val = '/content/drive/MyDrive/Thesis Dataset /Original dataset/validation /val-label-img'
original_masks_test = '/content/drive/MyDrive/Thesis Dataset /Original dataset/test/test-label-img'

"""##EDA"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg


# Define the mapping between denormalized pixel values and classes
pixel_value_to_class = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    6: 'Tree',
    7: 'Vehicle',
    8: 'Pool',
    9: 'Grass',
    # Add more mappings as needed
}

# Initialize a dictionary to store class counts
class_counts = {class_label: 0 for class_label in pixel_value_to_class.values()}

# Get a list of image files in the training data folder
image_files = os.listdir(training_data)

# Initialize a list to store denormalized pixel values
denormalized_pixel_values_list = []

# Count occurrences of each unique pixel value and save denormalized values
for image_file in image_files:
    image_path = os.path.join(training_data, image_file)
    img = mpimg.imread(image_path)
    unique_values = np.unique(img) * 255.0  # Assuming denormalization to [0, 255] range

    # Map unique pixel values to classes and update class counts
    for unique_value in unique_values:
        class_label = pixel_value_to_class.get(int(unique_value), 'Unknown')  # Convert to int for matching denormalized values
        class_counts[class_label] += 1  # Count each pixel separately

    # Append denormalized pixel values to the list
    denormalized_pixel_values_list.append(unique_values)

# Convert each sublist to a NumPy array
denormalized_pixel_values_array = [np.array(sublist) for sublist in denormalized_pixel_values_list]

# Save the denormalized pixel values as a NumPy array
np.save('/content/drive/MyDrive/Thesis Dataset /denormalized_pixel_values_training.npy', denormalized_pixel_values_list)

# Print class distribution
print("Class Distribution:")
for class_label, count in class_counts.items():
    print(f"{class_label}: {count} pixels")

fig, ax = plt.subplots(figsize=(10, 6))
bar_width = 0.5
bar_positions = np.arange(len(class_counts))

ax.bar(bar_positions, class_counts.values(), width=bar_width, align='center', tick_label=class_counts.keys())
ax.set_xticklabels(class_counts.keys(), rotation=45, ha="right")  # Rotate x-axis labels

ax.set_xlabel('Class')
ax.set_ylabel('Class Count')
ax.set_title('Class Distribution in Training Set')

plt.show()

import cv2
import os



# List the files in the directory
image_files = os.listdir(original_images_train)

# Create a set to store unique image sizes
unique_sizes = set()

for image_file in image_files:
    image_path = os.path.join(original_images_train, image_file)
    img = cv2.imread(image_path)

    # Check if the image file is valid
    if img is not None:
        height, width, _ = img.shape
        size_tuple = (height, width)
        unique_sizes.add(size_tuple)

# Print the unique image sizes
for size in unique_sizes:
    print(f"Unique Image Size: Height = {size[0]}, Width = {size[1]}")

"""##Pre-processing data

###Resize the images and masks(720*720)
"""

# Define the directory paths for the resized data
resized_train_dir = '/content/drive/MyDrive/Thesis Dataset/resized_train'
resized_val_dir = '/content/drive/MyDrive/Thesis Dataset/resized_val'
resized_test_dir = '/content/drive/MyDrive/Thesis Dataset/resized_test'

# Create the directories if they don't exist
os.makedirs(resized_train_dir, exist_ok=True)
os.makedirs(resized_val_dir, exist_ok=True)
os.makedirs(resized_test_dir, exist_ok=True)

# Within each resized data directory, create subdirectories for images and masks
os.makedirs(os.path.join(resized_train_dir, 'images'), exist_ok=True)
os.makedirs(os.path.join(resized_val_dir, 'images'), exist_ok=True)
os.makedirs(os.path.join(resized_test_dir, 'images'), exist_ok=True)
os.makedirs(os.path.join(resized_train_dir, 'masks'), exist_ok=True)
os.makedirs(os.path.join(resized_val_dir, 'masks'), exist_ok=True)
os.makedirs(os.path.join(resized_test_dir, 'masks'), exist_ok=True)


target_size = (720, 720)

# Define a function to resize images and masks and save them
def resize_images_and_masks(image_directory, mask_directory, target_size, output_dir):
    for filename in os.listdir(image_directory):
        if filename.endswith('.jpg'):  # Adjust the file extension if needed
            img_path = os.path.join(image_directory, filename)
            img = cv2.imread(img_path)
            if img is not None:
                resized_img = cv2.resize(img, target_size)
                img_output_path = os.path.join(output_dir, 'images', filename)
                cv2.imwrite(img_output_path, resized_img)

                # Load and resize the corresponding mask
                mask_path = os.path.join(mask_directory, filename.replace('.jpg', '_lab.png'))
                mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                if mask is not None:
                    resized_mask = cv2.resize(mask, target_size,interpolation=cv2.INTER_NEAREST)
                    mask_output_path = os.path.join(output_dir, 'masks', filename.replace('.jpg', '_lab.png'))
                    cv2.imwrite(mask_output_path, resized_mask)

# Call the function to resize and save images and masks for each dataset
resize_images_and_masks(original_images_train, original_masks_train, target_size, resized_train_dir)
resize_images_and_masks(original_images_val, original_masks_val, target_size, resized_val_dir)
resize_images_and_masks(original_images_test, original_masks_test, target_size, resized_test_dir)

"""###normalization"""

#check if the images are already normlized or not
import matplotlib.pyplot as plt
import cv2
import os

# Define the directory path for the images
image_directory = '/content/drive/MyDrive/Thesis Dataset /Resized_data /resized_train/images'

# Check the first 10 images
num_images_to_check = 10

# Create subplots with two rows
fig, axs = plt.subplots(2, 5, figsize=(15, 6))

for i, filename in enumerate(os.listdir(image_directory)):
    if i >= num_images_to_check:
        break  # Stop after loading 10 images

    if filename.endswith('.jpg'):
        # Load an image
        image_path = os.path.join(image_directory, filename)
        image = cv2.imread(image_path)

        if image is not None:
            # Display the image in the appropriate subplot
            row = i // 5
            col = i % 5
            axs[row, col].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
            axs[row, col].set_title(f"Image {i + 1}")

            # Show the pixel value range (min, max)
            pixel_range = (image.min(), image.max())
            axs[row, col].set_xlabel(f"Pixel Range: {pixel_range}")

# Hide any empty subplots
for i in range(num_images_to_check, 10):
    row = i // 5
    col = i % 5
    axs[row, col].axis('off')

plt.tight_layout()
plt.show()

#Normalization
import os
import cv2
import numpy as np

# Define the directory paths for the resized data
resized_train_dir = '/content/drive/MyDrive/Resized_data_720/resized_train'
resized_val_dir = '/content/drive/MyDrive/Resized_data_720/resized_val'
resized_test_dir = '/content/drive/MyDrive/Resized_data_720/resized_test'

def normalize_images_in_directory(directory):
    for filename in os.listdir(directory):
        if filename.endswith('.jpg'):
            # Load an image
            img_path = os.path.join(directory, filename)
            img = cv2.imread(img_path)

            if img is not None:
                # Normalize the image to the range [0, 1]
                img_normalized = img / 255.0

                # Save the normalized image back to the directory
                normalized_img_path = os.path.join(directory, filename)
                cv2.imwrite(normalized_img_path, (img_normalized * 255).astype(int))

# Call the function to normalize images in each directory
normalize_images_in_directory(resized_train_dir)
normalize_images_in_directory(resized_val_dir)
normalize_images_in_directory(resized_test_dir)

#check if the dataset is normalized between 0 and 1
import cv2
import numpy as np

# Load an image
img_path = '/content/drive/MyDrive/Resized_data_720/resized_train/images/10165.jpg'
img = cv2.imread(img_path)

if img is not None:
    # Check pixel value range
    pixel_min = img.min() / 255.0  # Scale to [0, 1]
    pixel_max = img.max() / 255.0  # Scale to [0, 1]

    print(f"Minimum Pixel Value: {pixel_min:.3f}")
    print(f"Maximum Pixel Value: {pixel_max:.3f}")
else:
    print("Error loading the image.")

"""###Class deduction"""

resized_masks_train = "/content/drive/MyDrive/Resized_data_720/resized_train/masks"
resized_masks_val = "/content/drive/MyDrive/Resized_data_720/resized_val/masks"
resized_masks_test = "/content/drive/MyDrive/Resized_data_720/resized_test/masks"

#set the classes moved to "Background" pixel values
background_class_value = 0

class_values_to_remove = [6, 8, 9]

def update_masks_in_directory(mask_directory):
    # Iterate through the mask images in the specified directory
    for filename in os.listdir(mask_directory):
        if filename.endswith('.png'):
            mask_path = os.path.join(mask_directory, filename)
            mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)

            if mask is not None:
                # Set pixels belonging to the missing classes to the background class value (0)
                for class_value_to_remove in class_values_to_remove:
                    mask[mask == class_value_to_remove] = background_class_value

                # Save the updated mask back to the directory
                cv2.imwrite(mask_path, mask)

# Update masks in your specified directories
update_masks_in_directory(resized_masks_train)
update_masks_in_directory(resized_masks_val)
update_masks_in_directory(resized_masks_test)

new_class_mapping = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    7: 'Vehicle'
}
#test on one sample
class_reduction_sample_directory= '/content/drive/MyDrive/Resized_data_720/resized_train/masks/6797_lab.png'
def display_single_mask(mask_path, title):
    mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
    if mask is not None:
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))
        # Display the mask
        axes[0].imshow(mask, cmap='viridis')
        axes[0].set_title(f"{title}")
        axes[0].axis('off')
        # Denormalize and display class labels
        unique_values, counts = np.unique(mask, return_counts=True)
        class_labels = [new_class_mapping.get(pixel_value, 'Unknown') for pixel_value in unique_values]
        class_info = [f"{label}: {count}" for label, count in zip(class_labels, counts)]
        class_labels_text = '\n'.join(class_info)
        axes[1].text(0.5, 0.5, f"Unique Values with Counts:\n{class_labels_text}", fontsize=12, ha='center')
        axes[1].axis('off')
        plt.show()

        return unique_values, counts  # Return the unique values and counts

# Display the single mask and get unique values with counts
unique_values, counts = display_single_mask(class_reduction_sample_directory, "Class_reduction_mask")

total_pixels = np.sum(counts)
for label, count in zip(unique_values, counts):
    class_label = new_class_mapping.get(label, 'Unknown')
    proportion = count / total_pixels
    print(f"Class Label: {class_label}, Count: {count}, Proportion: {proportion:.2%}")

mask = cv2.imread(class_reduction_sample_directory,cv2.IMREAD_UNCHANGED)

#original mask
original_class = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    6: 'Tree',
    7: 'Vehicle',
    8: 'Pool',
    9: 'Grass',

}
sample_directory= '/content/drive/MyDrive/Thesis Dataset /train-label-img/6797_lab.png'
def display_single_mask(mask_path, title):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is not None:
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))
        # Display the mask
        axes[0].imshow(mask, cmap='viridis')
        axes[0].set_title(f"{title}")
        axes[0].axis('off')
        # Calculate unique values and their counts
        unique_values, counts = np.unique(mask, return_counts=True)
        class_labels = [original_class.get(pixel_value, 'Unknown') for pixel_value in unique_values]
        class_info = [f"{label}: {count}" for label, count in zip(class_labels, counts)]
        class_labels_text = '\n'.join(class_info)
        axes[1].text(0.5, 0.5, f"Unique Values with Counts:\n{class_labels_text}", fontsize=12, ha='center')
        axes[1].axis('off')
        plt.show()

        return unique_values, counts  # Return the unique values and counts

# Display the single mask and get unique values with counts
unique_values, counts = display_single_mask(sample_directory, "original_Mask")


total_pixels = np.sum(counts)
for label, count in zip(unique_values, counts):
    class_label = original_class.get(label, 'Unknown')
    proportion = count / total_pixels
    print(f"Class Label: {class_label}, Count: {count}, Proportion: {proportion:.2%}")

#resized mask
resized_sample_directory= '/content/drive/MyDrive/Thesis Dataset /Resized_data /resized_train/masks/6797_lab.png'
def display_single_mask(mask_path, title):
    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
    if mask is not None:
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))
        # Display the mask
        axes[0].imshow(mask, cmap='viridis')
        axes[0].set_title(f"{title}")
        axes[0].axis('off')
        # Denormalize and display class labels
        unique_values, counts = np.unique(mask, return_counts=True)
        class_labels = [original_class.get(pixel_value, 'Unknown') for pixel_value in unique_values]
        class_info = [f"{label}: {count}" for label, count in zip(class_labels, counts)]
        class_labels_text = '\n'.join(class_info)
        axes[1].text(0.5, 0.5, f"Unique Values with Counts:\n{class_labels_text}", fontsize=12, ha='center')
        axes[1].axis('off')
        plt.show()

        return unique_values, counts  # Return the unique values and counts

# Display the single mask and get unique values with counts
unique_values, counts = display_single_mask(resized_sample_directory, "Resized_mask")

total_pixels = np.sum(counts)
for label, count in zip(unique_values, counts):
    class_label = original_class.get(label, 'Unknown')
    proportion = count / total_pixels
    print(f"Class Label: {class_label}, Count: {count}, Proportion: {proportion:.2%}")

