# -*- coding: utf-8 -*-
"""Prediction_display .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CmoVcV5HRtVAwnvRdyrSjoVe4bQ0nX45
"""

import os
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import cv2
from google.colab.patches import cv2_imshow
import tensorflow as tf
from tensorflow.keras.optimizers.schedules import PolynomialDecay
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.metrics import MeanIoU

!pip install q keras==2.14.0

from google.colab import drive
drive.mount('/content/drive')

test_image_path ="/content/drive/MyDrive/Resized_data_720/resized_test/images/6695.jpg"
test_mask_path = "/content/drive/MyDrive/Resized_data_720/resized_test/masks/6695_lab.png"

test_image = cv2.imread(test_image_path)
test_mask = cv2.imread(test_mask_path, cv2.IMREAD_GRAYSCALE)

X_test = np.array(test_image)
y_test = np.array(test_mask)
np.save('/content/drive/MyDrive/X_test.npy', X_test)
np.save('/content/drive/MyDrive/y_test.npy', y_test)

X_test = np.load('/content/drive/MyDrive/X_test.npy')
y_test = np.load('/content/drive/MyDrive/X_test.npy')

num_classes = 7
y_test_reshaped = np.zeros((y_test.shape[0], y_test.shape[1], y_test.shape[2], num_classes), dtype=np.uint8)

# Iterate over each class and create the respective channel
for class_idx in range(num_classes):
    y_test_reshaped[:, :, :, class_idx] = (y_test == class_idx).astype(np.uint8)

pip install segmentation-models

import os
os.environ["SM_FRAMEWORK"] = "tf.keras"

from tensorflow import keras
import segmentation_models as sm
from segmentation_models import PSPNet
from segmentation_models.losses import CategoricalFocalLoss


teacher_model = PSPNet(backbone_name='resnet101',
                       classes= 7, input_shape=(720, 720, 3),
                       activation='softmax',
                       encoder_weights='imagenet',
                       downsample_factor= 4,
                       psp_conv_filters = 64,
                       psp_pooling_type='avg',
                       psp_dropout=None
                       )

num_classes = 7

import tensorflow as tf
from tensorflow.keras.optimizers.schedules import PolynomialDecay
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.metrics import MeanIoU

# Define your learning rate schedule with the given parameters
base_learning_rate = 0.0001
momentum = 0.9
weight_decay = 0.0001
power = 0.9
auxiliary_loss_weight = 0.4

# Calculate the total number of training steps (you need to adjust this based on your dataset and batch size)
total_steps = 100

learning_rate_schedule = PolynomialDecay(
    initial_learning_rate=base_learning_rate,
    decay_steps=total_steps,
    end_learning_rate=0,  # You can set this to 0 or any other final learning rate you desire
    power=power
)

# Create the legacy Adam optimizer with the specified momentum and weight decay
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule, beta_1=momentum, beta_2=0.999, epsilon=1e-7, weight_decay=weight_decay)

# Compile your model using the custom optimizer and loss
teacher_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[MeanIoU(num_classes=num_classes)])

history = teacher_model.fit(X_train, y_train_reshaped,
                            validation_data=(X_val, y_val_reshaped),
                            epochs=2
                            )

from tensorflow.keras.models import load_model

teacher_model_trained = load_model("/content/drive/MyDrive/models/student_model_no_KD_64_nobatchnorm_200.keras")

student_model_trained = load_model("/content/drive/MyDrive/models/KD_mobilenet_64_no_batchnorm_200")

# Define your learning rate schedule with the given parameters
base_learning_rate = 0.0001
momentum = 0.9
weight_decay = 0.0001
power = 0.9
auxiliary_loss_weight = 0.4

# Calculate the total number of training steps (you need to adjust this based on your dataset and batch size)
total_steps = 10000

learning_rate_schedule = PolynomialDecay(
    initial_learning_rate=base_learning_rate,
    decay_steps=total_steps,
    end_learning_rate=0,  # You can set this to 0 or any other final learning rate you desire
    power=power
)

# Create the legacy Adam optimizer with the specified momentum and weight decay
optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_schedule, beta_1=momentum, beta_2=0.999, epsilon=1e-7, weight_decay=weight_decay)

# Compile your model using the custom optimizer and loss
student_model_trained.compile(optimizer=optimizer, loss=tf.keras.losses.CategoricalFocalCrossentropy(),
                      metrics=[tf.keras.metrics.OneHotMeanIoU(num_classes=num_classes)])

from google.colab.patches import cv2_imshow
class_mapping = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    7: 'Vehicle'
}

prediction = student_model_trained.predict(X_test.reshape(1,720, 720, 3))


def combine_channels(prediction):
    # Combine channels by selecting the channel with the highest probability (argmax)
    combined_mask = np.argmax(prediction, axis=-1)
    return combined_mask

def display_single_mask(mask, title):
    if mask is not None:
        fig, axes = plt.subplots(1, 1, figsize=(8, 8))
        # Display the mask
        axes.imshow(mask[0], cmap='viridis')
        axes.set_title(f"{title}")
        axes.axis('off')
        plt.show()


# Combine the channels and display the single mask
combined_mask = combine_channels(prediction)
display_single_mask(combined_mask, "predicted_mask")

new_class_mapping = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    7: 'Vehicle'
}

from matplotlib.colors import ListedColormap

custom_colors = [
    (1.0, 0.9137, 0.9569),  # pink
    (1.0,0,0), #Red
    (1.0, 0.6471, 0), #  Orange
    (float(128/255), float(128/255), 0),       # Olives
    (0.5, 0.5, 0.5),   # Grey
     (0.678, 0.847, 0.902),  # Light Blue
]
custom_cmap = ListedColormap(custom_colors)
#test on one sample


def display_single_mask(mask, title):

    if mask is not None:
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))
        # Display the mask
        axes[0].imshow(mask, cmap=custom_cmap)
        axes[0].set_title(f"{title}")
        axes[0].axis('off')
        # Denormalize and display class labels
        unique_values, counts = np.unique(mask, return_counts=True)
        class_labels = [new_class_mapping.get(pixel_value, 'Unknown') for pixel_value in unique_values]
        class_info = [f"{label}: {count}" for label, count in zip(class_labels, counts)]
        class_labels_text = '\n'.join(class_info)
        axes[1].text(0.5, 0.5, f"Unique Values with Counts:\n{class_labels_text}", fontsize=12, ha='center')
        axes[1].axis('off')
        plt.show()

        return unique_values, counts  # Return the unique values and counts

# Display the single mask and get unique values with counts
unique_values, counts = display_single_mask(combined_mask[0] , "student_64_200")

total_pixels = np.sum(counts)
for label, count in zip(unique_values, counts):
    class_label = new_class_mapping.get(label, 'Unknown')
    proportion = count / total_pixels
    print(f"Class Label: {class_label}, Count: {count}, Proportion: {proportion:.2%}")

unique_values

from matplotlib.colors import ListedColormap
new_class_mapping = {
    0: 'Background',
    1: 'Building-flooded',
    2: 'Building-non-flooded',
    3: 'Road-flooded',
    4: 'Road-non-flooded',
    5: 'Water',
    7: 'Vehicle'
}

custom_colors = [
    (1.0, 0.9137, 0.9569),  # pink
    (1.0,0,0), #Red
    (1.0, 0.6471, 0), #  Orange
    (float(128/255), float(128/255), 0),       # Olives
    (float(128/255), float(128/255), 0),       # Olives
    (0.678, 0.847, 0.902),  # Light Blue
    (0.678, 0.847, 0.902),  # Light Blue
    (0.5, 0, 0.5),           # Purple
]
custom_cmap = ListedColormap(custom_colors)
#test on one sample
class_reduction_sample_directory= '/content/drive/MyDrive/Resized_data_720/resized_test/masks/6695_lab.png'
def display_single_mask(mask_path, title):
    mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
    if mask is not None:
        fig, axes = plt.subplots(2, 1, figsize=(8, 8))
        # Display the mask
        axes[0].imshow(mask, cmap=custom_cmap
                       )
        axes[0].set_title(f"{title}")
        axes[0].axis('off')
        # Denormalize and display class labels
        unique_values, counts = np.unique(mask, return_counts=True)
        class_labels = [new_class_mapping.get(pixel_value, 'Unknown') for pixel_value in unique_values]
        class_info = [f"{label}: {count}" for label, count in zip(class_labels, counts)]
        class_labels_text = '\n'.join(class_info)
        axes[1].text(0.5, 0.5, f"Unique Values with Counts:\n{class_labels_text}", fontsize=12, ha='center')
        axes[1].axis('off')
        plt.show()

        return unique_values, counts  # Return the unique values and counts

# Display the single mask and get unique values with counts
unique_values, counts = display_single_mask(class_reduction_sample_directory, "Class_reduction_mask")

total_pixels = np.sum(counts)
for label, count in zip(unique_values, counts):
    class_label = new_class_mapping.get(label, 'Unknown')
    proportion = count / total_pixels
    print(f"Class Label: {class_label}, Count: {count}, Proportion: {proportion:.2%}")